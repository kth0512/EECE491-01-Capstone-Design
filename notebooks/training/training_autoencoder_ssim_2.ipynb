{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1391,"status":"ok","timestamp":1764747560911,"user":{"displayName":"종합설계","userId":"01573912834551956230"},"user_tz":-540},"id":"T8QOVrMmu4kM","outputId":"4a4913f3-ff63-40fe-a48d-ca316837af04"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","import sys\n","\n","PROJECT_ROOT = '/content/drive/MyDrive/commit_test_folder/EECE491-01-Capstone-Design'\n","\n","drive.mount('/content/drive')\n","sys.path.append(PROJECT_ROOT)"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"elapsed":4296,"status":"ok","timestamp":1764747567358,"user":{"displayName":"종합설계","userId":"01573912834551956230"},"user_tz":-540},"id":"TjRQfEAZA6GS","outputId":"74786a7f-5ed9-4b5b-b1b1-9dbcde82530d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: piqa in /usr/local/lib/python3.12/dist-packages (1.3.2)\n","Requirement already satisfied: torch\u003e=1.12.0 in /usr/local/lib/python3.12/dist-packages (from piqa) (2.9.0+cu126)\n","Requirement already satisfied: torchvision\u003e=0.13.0 in /usr/local/lib/python3.12/dist-packages (from piqa) (0.24.0+cu126)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch\u003e=1.12.0-\u003epiqa) (3.20.0)\n","Requirement already satisfied: typing-extensions\u003e=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch\u003e=1.12.0-\u003epiqa) (4.15.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch\u003e=1.12.0-\u003epiqa) (75.2.0)\n","Requirement already satisfied: sympy\u003e=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch\u003e=1.12.0-\u003epiqa) (1.14.0)\n","Requirement already satisfied: networkx\u003e=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch\u003e=1.12.0-\u003epiqa) (3.6)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch\u003e=1.12.0-\u003epiqa) (3.1.6)\n","Requirement already satisfied: fsspec\u003e=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch\u003e=1.12.0-\u003epiqa) (2025.3.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch\u003e=1.12.0-\u003epiqa) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch\u003e=1.12.0-\u003epiqa) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch\u003e=1.12.0-\u003epiqa) (12.6.80)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch\u003e=1.12.0-\u003epiqa) (9.10.2.21)\n","Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch\u003e=1.12.0-\u003epiqa) (12.6.4.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch\u003e=1.12.0-\u003epiqa) (11.3.0.4)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch\u003e=1.12.0-\u003epiqa) (10.3.7.77)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch\u003e=1.12.0-\u003epiqa) (11.7.1.2)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch\u003e=1.12.0-\u003epiqa) (12.5.4.2)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch\u003e=1.12.0-\u003epiqa) (0.7.1)\n","Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch\u003e=1.12.0-\u003epiqa) (2.27.5)\n","Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch\u003e=1.12.0-\u003epiqa) (3.3.20)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch\u003e=1.12.0-\u003epiqa) (12.6.77)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch\u003e=1.12.0-\u003epiqa) (12.6.85)\n","Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch\u003e=1.12.0-\u003epiqa) (1.11.1.6)\n","Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch\u003e=1.12.0-\u003epiqa) (3.5.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision\u003e=0.13.0-\u003epiqa) (2.0.2)\n","Requirement already satisfied: pillow!=8.3.*,\u003e=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision\u003e=0.13.0-\u003epiqa) (11.3.0)\n","Requirement already satisfied: mpmath\u003c1.4,\u003e=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy\u003e=1.13.3-\u003etorch\u003e=1.12.0-\u003epiqa) (1.3.0)\n","Requirement already satisfied: MarkupSafe\u003e=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2-\u003etorch\u003e=1.12.0-\u003epiqa) (3.0.3)\n"]}],"source":["!pip install piqa"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":3689,"status":"ok","timestamp":1764747571063,"user":{"displayName":"종합설계","userId":"01573912834551956230"},"user_tz":-540},"id":"-smFl9aJAqXs"},"outputs":[],"source":["import os\n","import time\n","import random\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import torchvision.transforms as transforms\n","\n","import matplotlib.pyplot as plt\n","from matplotlib.ticker import MultipleLocator\n","from piqa.ssim import SSIM\n","\n","from src.utils.data_utils import get_dataloaders, prepare_dataset\n","from src.utils.channels import awgn_channel\n","from src.utils.viz_utils import plot_loss\n","from src.models.face_autoencoder import FaceAutoencoder\n"]},{"cell_type":"markdown","metadata":{"id":"x4aqDWhbmM-b"},"source":["This cell prepares the Colab environment by copying and extracting the dataset from Google Drive to the fast local SSD."]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"elapsed":9,"status":"ok","timestamp":1764747572504,"user":{"displayName":"종합설계","userId":"01573912834551956230"},"user_tz":-540},"id":"UVMbH_klug9n","outputId":"f8c83790-cf96-4419-cecc-f8999489e5e3"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Starting data setup...\n","Data directory /content/celeba_dataset/content/cropped_celeba already exists. Skipping copy/untar.\n","Data setup finished in 0.00 seconds.\n","Successfully found data at: /content/celeba_dataset/content/cropped_celeba\n"]}],"source":["DRIVE_ARCHIVE_PATH = \"/content/drive/MyDrive/datasets/cropped_celeba.tar\"\n","LOCAL_ARCHIVE_PATH = \"/content/cropped_celeba.tar\"\n","EXTRACT_PATH = \"/content/celeba_dataset\"\n","\n","LOCAL_DATA_DIR = prepare_dataset(DRIVE_ARCHIVE_PATH, LOCAL_ARCHIVE_PATH, EXTRACT_PATH)"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":526,"status":"ok","timestamp":1764747575065,"user":{"displayName":"종합설계","userId":"01573912834551956230"},"user_tz":-540},"id":"USLmmEg_uihK","outputId":"b6673df3-b659-4e20-e8f6-becc468b0b8f"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Loading dataset from: /content/celeba_dataset/content/cropped_celeba\n","Searching for '*.jpg' files in: /content/celeba_dataset/content/cropped_celeba\n","Successfully found 199509 images.\n","Successfully loaded 199509 total images.\n","Splitting dataset into:\n","  Train: 159607 images\n","  Validation: 19950 images\n","  Test: 19952 images\n","\n","DataLoaders created successfully.\n"]}],"source":["DATA_ROOT = LOCAL_DATA_DIR\n","BATCH_SIZE = 256\n","IMAGE_SIZE = 128\n","RANDOM_SEED = 42\n","\n","# Get dataloaders\n","train_loader, val_loader, test_loader = get_dataloaders(\n","    root_dir=DATA_ROOT,\n","    batch_size=BATCH_SIZE,\n","    image_size=IMAGE_SIZE,\n","    random_seed=RANDOM_SEED\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"waGWXH1BdGzK"},"outputs":[{"name":"stdout","output_type":"stream","text":["Using device: cuda\n","Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 44.7M/44.7M [00:00\u003c00:00, 115MB/s]\n"]},{"name":"stdout","output_type":"stream","text":["Start training...\n","Epoch [1/50], Train Loss: 0.543080, Val Loss: 0.563743\n"," -\u003e New best validation loss! Saving model\n","Epoch [2/50], Train Loss: 0.450088, Val Loss: 0.422934\n"," -\u003e New best validation loss! Saving model\n","Epoch [3/50], Train Loss: 0.345119, Val Loss: 0.382675\n"," -\u003e New best validation loss! Saving model\n","Epoch [4/50], Train Loss: 0.305554, Val Loss: 0.352284\n"," -\u003e New best validation loss! Saving model\n","Epoch [5/50], Train Loss: 0.279394, Val Loss: 0.338721\n"," -\u003e New best validation loss! Saving model\n","Epoch [6/50], Train Loss: 0.263946, Val Loss: 0.330226\n"," -\u003e New best validation loss! Saving model\n","Epoch [7/50], Train Loss: 0.252755, Val Loss: 0.316607\n"," -\u003e New best validation loss! Saving model\n","Epoch [8/50], Train Loss: 0.243325, Val Loss: 0.310479\n"," -\u003e New best validation loss! Saving model\n","Epoch [9/50], Train Loss: 0.236628, Val Loss: 0.334966\n","Epoch [10/50], Train Loss: 0.233136, Val Loss: 0.295813\n"," -\u003e New best validation loss! Saving model\n","Epoch [11/50], Train Loss: 0.227956, Val Loss: 0.284837\n"," -\u003e New best validation loss! Saving model\n","Epoch [12/50], Train Loss: 0.220915, Val Loss: 0.283292\n"," -\u003e New best validation loss! Saving model\n","Epoch [13/50], Train Loss: 0.218330, Val Loss: 0.279747\n"," -\u003e New best validation loss! Saving model\n","Epoch [14/50], Train Loss: 0.214228, Val Loss: 0.312271\n","Epoch [15/50], Train Loss: 0.210986, Val Loss: 0.270555\n"," -\u003e New best validation loss! Saving model\n","Epoch [16/50], Train Loss: 0.205453, Val Loss: 0.284909\n","Epoch [17/50], Train Loss: 0.202250, Val Loss: 0.271912\n","Epoch [18/50], Train Loss: 0.201445, Val Loss: 0.268324\n"," -\u003e New best validation loss! Saving model\n","Epoch [19/50], Train Loss: 0.197129, Val Loss: 0.257387\n"," -\u003e New best validation loss! Saving model\n","Epoch [20/50], Train Loss: 0.195653, Val Loss: 0.258306\n","Epoch [21/50], Train Loss: 0.191583, Val Loss: 0.258250\n","Epoch [22/50], Train Loss: 0.190759, Val Loss: 0.253598\n"," -\u003e New best validation loss! Saving model\n","Epoch [23/50], Train Loss: 0.187662, Val Loss: 0.253454\n"," -\u003e New best validation loss! Saving model\n","Epoch [24/50], Train Loss: 0.187063, Val Loss: 0.249339\n"," -\u003e New best validation loss! Saving model\n","Epoch [25/50], Train Loss: 0.184421, Val Loss: 0.249737\n","Epoch [26/50], Train Loss: 0.183628, Val Loss: 0.247162\n"," -\u003e New best validation loss! Saving model\n","Epoch [27/50], Train Loss: 0.181265, Val Loss: 0.249833\n","Epoch [28/50], Train Loss: 0.178622, Val Loss: 0.244675\n"," -\u003e New best validation loss! Saving model\n","Epoch [29/50], Train Loss: 0.178638, Val Loss: 0.248294\n","Epoch [30/50], Train Loss: 0.178524, Val Loss: 0.249595\n","Epoch [31/50], Train Loss: 0.177687, Val Loss: 0.248540\n","Epoch [32/50], Train Loss: 0.173626, Val Loss: 0.243136\n"," -\u003e New best validation loss! Saving model\n","Epoch [33/50], Train Loss: 0.173192, Val Loss: 0.259144\n","Epoch [34/50], Train Loss: 0.172784, Val Loss: 0.239691\n"," -\u003e New best validation loss! Saving model\n","Epoch [35/50], Train Loss: 0.171802, Val Loss: 0.239117\n"," -\u003e New best validation loss! Saving model\n","Epoch [36/50], Train Loss: 0.169680, Val Loss: 0.239971\n","Epoch [37/50], Train Loss: 0.168551, Val Loss: 0.238227\n"," -\u003e New best validation loss! Saving model\n","Epoch [38/50], Train Loss: 0.167759, Val Loss: 0.238872\n","Epoch [39/50], Train Loss: 0.168366, Val Loss: 0.302629\n","Epoch [40/50], Train Loss: 0.168632, Val Loss: 0.233609\n"," -\u003e New best validation loss! Saving model\n","Epoch [41/50], Train Loss: 0.164877, Val Loss: 0.234452\n","Epoch [42/50], Train Loss: 0.172123, Val Loss: 0.232263\n"," -\u003e New best validation loss! Saving model\n","Epoch [43/50], Train Loss: 0.166245, Val Loss: 0.229578\n"," -\u003e New best validation loss! Saving model\n","Epoch [44/50], Train Loss: 0.163689, Val Loss: 0.229407\n"," -\u003e New best validation loss! Saving model\n","Epoch [45/50], Train Loss: 0.162591, Val Loss: 0.229806\n","Epoch [46/50], Train Loss: 0.164512, Val Loss: 0.228708\n"," -\u003e New best validation loss! Saving model\n","Epoch [47/50], Train Loss: 0.163493, Val Loss: 0.226879\n"," -\u003e New best validation loss! Saving model\n","Epoch [48/50], Train Loss: 0.161106, Val Loss: 0.228293\n","Epoch [49/50], Train Loss: 0.161193, Val Loss: 0.227945\n","Epoch [50/50], Train Loss: 0.160648, Val Loss: 0.226204\n"," -\u003e New best validation loss! Saving model\n","--- Training finished. ---\n","Best validation loss achieved: 0.226204\n","Best model saved to /content/drive/MyDrive/models/face_autoencoder_512_SSIM_Augmentation.pth\n"]}],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"Using device: {device}\")\n","\n","model = FaceAutoencoder(latent_dim=512).to(device)\n","optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n","criterion = SSIM(n_channels=3).to(device) # n_channels = 3: RGB image\n","\n","# Training parameters\n","num_epochs = 50\n","MIN_SNR_DB = 0.0\n","MAX_SNR_DB = 20.0\n","\n","# Save directory\n","SAVE_DIR = \"/content/drive/MyDrive/models\"\n","MODEL_PATH = os.path.join(SAVE_DIR, \"face_autoencoder_512_SSIM_Augmentation.pth\")\n","os.makedirs(SAVE_DIR, exist_ok=True)\n","\n","best_val_loss = float('inf') # initial value is infinity\n","train_loss_history = []\n","val_loss_history = []\n","\n","print(\"Start training...\")\n","SNR_POINTS_FOR_VAL = [0.0, 5.0, 10.0, 15.0, 20.0]\n","NUM_VAL_POINTS = len(SNR_POINTS_FOR_VAL)\n","\n","for epoch in range(num_epochs):\n","\n","    # Traning Phase\n","    model.train()\n","    total_train_loss = 0\n","\n","    for images, _ in train_loader:\n","        images = images.to(device)\n","\n","        latent_vector = model.encode(images)\n","\n","        current_snr_db = random.uniform(MIN_SNR_DB, MAX_SNR_DB)\n","        noisy_vector = awgn_channel(latent_vector, snr_db=current_snr_db)\n","\n","        reconstructed_images = model.decode(noisy_vector)\n","\n","        # Rescailing [-1, 1] into [0, 1]\n","        recon_rescaled = (reconstructed_images + 1.0) / 2.0\n","        images_rescaled = (images + 1.0) / 2.0\n","\n","        ssim_value = criterion(recon_rescaled, images_rescaled)\n","        loss = 1.0 - ssim_value\n","\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","        total_train_loss += loss.item()\n","\n","    avg_train_loss = total_train_loss / len(train_loader)\n","\n","    # Validation Phase\n","    model.eval()\n","    total_combined_loss = 0\n","    with torch.no_grad():\n","        for val_images, _ in val_loader:\n","            val_images = val_images.to(device)\n","            for fixed_snr_db in SNR_POINTS_FOR_VAL:\n","                latent_vector = model.encode(val_images)\n","                noisy_vector = awgn_channel(latent_vector, snr_db=fixed_snr_db)\n","\n","                reconstructed_images = model.decode(noisy_vector)\n","\n","                # Rescailing [-1, 1] into [0, 1]\n","                reconstructed_images_rescaled = (reconstructed_images + 1.0) / 2.0\n","                val_images_rescaled = (val_images + 1.0) / 2.0\n","\n","                val_ssim_value = criterion(reconstructed_images_rescaled, val_images_rescaled)\n","                val_loss = 1.0 - val_ssim_value\n","                total_combined_loss += val_loss.item()\n","\n","    avg_val_loss = total_combined_loss / (len(val_loader) * NUM_VAL_POINTS)\n","\n","    train_loss_history.append(avg_train_loss)\n","    val_loss_history.append(avg_val_loss)\n","\n","    print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {avg_train_loss:.6f}, Val Loss: {avg_val_loss:.6f}\")\n","\n","    # Save best model (criterion: validation loss)\n","    if avg_val_loss \u003c best_val_loss:\n","        best_val_loss = avg_val_loss\n","        print(f\" -\u003e New best validation loss! Saving model\")\n","        torch.save(model.state_dict(), MODEL_PATH)\n","\n","print(\"--- Training finished. ---\")\n","print(f\"Best validation loss achieved: {best_val_loss:.6f}\")\n","print(f\"Best model saved to {MODEL_PATH}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"LfyXQZnYPx8D"},"outputs":[{"ename":"NameError","evalue":"name 'plt' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-1332580806.py\u001b[0m in \u001b[0;36m\u003ccell line: 0\u003e\u001b[0;34m()\u001b[0m\n\u001b[0;32m----\u003e 1\u001b[0;31m \u001b[0mplot_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss_history\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loss_history\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/content/drive/MyDrive/commit_test_folder/EECE491-01-Capstone-Design/src/utils/viz_utils.py\u001b[0m in \u001b[0;36mplot_loss\u001b[0;34m(num_epochs, train_loss_history, val_loss_history)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mplot_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss_history\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loss_history\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;31m# plot train loss, val loss vs epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---\u003e 25\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     plt.plot(range(1, num_epochs + 1), train_loss_history, label='Train Loss',\n\u001b[1;32m     27\u001b[0m             linestyle='--', color='green', marker='o', markersize=4)\n","\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"]}],"source":["plot_loss(num_epochs, train_loss_history, val_loss_history)"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyMYPmcYY8oE1HT+QxCA7j2O","gpuType":"A100","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}